{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(iris.data,iris.target,\n",
    "                                                 train_size=0.8,random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#建模\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = accuracy_score(y_true=y_test,y_pred=y_pred)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31miris.txt\u001b[m\u001b[m*              朴素贝叶斯.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3               4\n",
       "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
       "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
       "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
       "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
       "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
       "..   ...  ...  ...  ...             ...\n",
       "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据导入\n",
    "dataset = pd.read_csv('iris.txt',delimiter=',',header=None)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#切分训练集和测试集\n",
    "\n",
    "def cutAndshuffle_dataset(dataset,rate=0.8):\n",
    "    m = dataset.shape[0]\n",
    "    n = dataset.shape[1]\n",
    "    indexs = list(dataset.index)\n",
    "    random.shuffle(indexs)\n",
    "    dataset.index = indexs\n",
    "    train_size = int(rate*m)\n",
    "    x_train = dataset.loc[range(train_size),:]\n",
    "    x_test = dataset.loc[range(train_size,m),:]\n",
    "    x_test.index = range(m-train_size)\n",
    "    # print(\"切分完成\")\n",
    "    return x_train,x_train.iloc[:,-1],x_test,x_test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切分完成\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3                4\n",
       "0    5.7  2.5  5.0  2.0   Iris-virginica\n",
       "1    5.2  4.1  1.5  0.1      Iris-setosa\n",
       "2    5.7  2.8  4.1  1.3  Iris-versicolor\n",
       "3    5.2  3.5  1.5  0.2      Iris-setosa\n",
       "4    5.6  3.0  4.5  1.5  Iris-versicolor\n",
       "..   ...  ...  ...  ...              ...\n",
       "115  5.0  3.4  1.6  0.4      Iris-setosa\n",
       "116  5.8  2.7  5.1  1.9   Iris-virginica\n",
       "117  6.7  3.1  4.4  1.4  Iris-versicolor\n",
       "118  6.7  3.3  5.7  2.5   Iris-virginica\n",
       "119  6.0  2.9  4.5  1.5  Iris-versicolor\n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test = cutAndshuffle_dataset(dataset)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建模 构建高斯朴素贝叶斯分类器\n",
    "def train_nbclassifier(x_train,x_test):\n",
    "    labels = y_train.value_counts().index\n",
    "    m = x_train.shape[0]\n",
    "    n = x_train.shape[1]\n",
    "    all_means = []\n",
    "    all_stds = []\n",
    "    for label in labels:\n",
    "        x_temp = x_train[x_train.iloc[:,-1] == label]\n",
    "        x_mean = x_temp.mean()\n",
    "        x_std = np.sum(((x_temp.iloc[:,:-1] - x_mean)**2)/x_temp.shape[0])\n",
    "        all_means.append(x_mean)\n",
    "        all_stds.append(x_std)\n",
    "    means = pd.DataFrame(all_means,index = labels)\n",
    "    stds = pd.DataFrame(all_stds,index=labels)\n",
    "    results = []\n",
    "    # print(stds)\n",
    "    for i in range(x_test.shape[0]):\n",
    "        item = x_test.iloc[i,:-1].tolist()\n",
    "        prob = np.exp(-1*(item-means)/(2*stds))/(np.sqrt(2*np.pi*stds))\n",
    "        # probs.append(prob)\n",
    "        item_p = 1.0\n",
    "        # print(prob)\n",
    "        for j in range(n-1):\n",
    "            item_p *= prob.iloc[:,j]\n",
    "            #print(item_p)\n",
    "        results.append(np.argmax(item_p))\n",
    "    # print(results)\n",
    "    # 计算准确率\n",
    "    socres = accuracy_score(x_test.iloc[:,-1],results)\n",
    "    # print(scores)\n",
    "    return scores\n",
    "    \n",
    "# train_nbclassifier(x_train,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试模型效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切分完成\n",
      "0.9666666666666667\n",
      "切分完成\n",
      "0.9666666666666667\n",
      "切分完成\n",
      "0.9666666666666667\n",
      "切分完成\n",
      "0.9666666666666667\n",
      "切分完成\n",
      "0.9666666666666667\n",
      "切分完成\n",
      "0.9666666666666667\n",
      "切分完成\n",
      "0.9666666666666667\n",
      "切分完成\n",
      "0.9666666666666667\n",
      "切分完成\n",
      "0.9666666666666667\n",
      "切分完成\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "def test_performance(dataset):\n",
    "    scores = 0.0\n",
    "    i = 0\n",
    "    while i <10:\n",
    "        x_train,y_train,x_test,y_test = cutAndshuffle_dataset(dataset)\n",
    "        score = train_nbclassifier(x_train,x_test)\n",
    "        print(score)\n",
    "        i += 1\n",
    "\n",
    "test_performance(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. 构建词向量\\n2. 构建词汇表\\n3. 生成训练集词向量列表\\n4. 朴素贝叶斯分类器训练\\n5. 模型测试\\n6. 模型优化\\n'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文档分类\n",
    "\n",
    "\"\"\"\n",
    "1. 构建词向量\n",
    "2. 构建词汇表\n",
    "3. 生成训练集词向量列表\n",
    "4. 朴素贝叶斯分类器训练\n",
    "5. 模型测试\n",
    "6. 模型优化\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 创建实验数据集\n",
    "def build_dataset():\n",
    "    doc_dataset=[\n",
    "        ['my','dog','has','flea','problems','help','please'],\n",
    "        ['maybe','not','take','him','to','dog','park','stupid'],\n",
    "        ['my','dalmation','is','so','cute','I','love','him'],\n",
    "        ['stop','posting','stupid','worthless','garbage'],\n",
    "        ['mr','licks','ate','my','steak','how','to','stop','him'],\n",
    "        ['quit','buying','worthlsess','dog','food','stupid']\n",
    "    ]\n",
    "    doc_classVec=[0,1,0,1,0,1] #0代表正常言论，1代表侮辱性文字\n",
    "    return doc_dataset,doc_classVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dataset = None\n",
    "doc_classVec = None\n",
    "doc_dataset,doc_classVec = build_dataset()\n",
    "doc_classVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 生成词汇表\n",
    "def build_voc_table(doc_dataset):\n",
    "    voc_list = set()\n",
    "    freq_dict = {}\n",
    "#     for i in range(len(doc_dataset)):\n",
    "#         for j in doc_dataset[i]:\n",
    "#             if freq_dict.get(j):\n",
    "#                 freq_dict[j] += 1\n",
    "#             else:\n",
    "#                 freq_dict[j] = 1\n",
    "#                 voc_list.append(j)\n",
    "    for i in doc_dataset:\n",
    "        voc_list  = voc_list | set(i)\n",
    "    voc_list = list(voc_list)\n",
    "    return voc_list,freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['has',\n",
       " 'dog',\n",
       " 'is',\n",
       " 'not',\n",
       " 'I',\n",
       " 'quit',\n",
       " 'problems',\n",
       " 'so',\n",
       " 'to',\n",
       " 'mr',\n",
       " 'how',\n",
       " 'help',\n",
       " 'stop',\n",
       " 'garbage',\n",
       " 'maybe',\n",
       " 'my',\n",
       " 'dalmation',\n",
       " 'cute',\n",
       " 'steak',\n",
       " 'worthless',\n",
       " 'stupid',\n",
       " 'please',\n",
       " 'ate',\n",
       " 'love',\n",
       " 'take',\n",
       " 'licks',\n",
       " 'posting',\n",
       " 'flea',\n",
       " 'food',\n",
       " 'worthlsess',\n",
       " 'buying',\n",
       " 'park',\n",
       " 'him']"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_list = []\n",
    "freq_dict = {}\n",
    "voc_list,freq_dict = build_voc_table(doc_dataset)\n",
    "voc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 生成句子向量\n",
    "def build_senvec(voc_list,sens):\n",
    "    m = len(voc_list)\n",
    "    n = len(sens)\n",
    "    sensVec = []\n",
    "    for k in range(n):\n",
    "#       senVec = np.zeros(m)\n",
    "        senVec = [0]*m\n",
    "#         senVec.reshape(1,m)\n",
    "        for i in range(len(sens[k])):\n",
    "            word = sens[k][i]\n",
    "            idx = voc_list.index(word)\n",
    "            senVec[idx] =1\n",
    "#       print(senVec)\n",
    "        sensVec.append(senVec)\n",
    "    return sensVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensVec = None\n",
    "sensVec = build_senvec(voc_list,doc_dataset)\n",
    "len(sensVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-402-7912b1e934a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "b = [2,2,3,4,1]\n",
    "b.index[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 构建分类器\n",
    "from functools import reduce\n",
    "\"\"\"\n",
    "1. 计算所有文档中是垃圾文档的概率（先验）\n",
    "2. 分别计算垃圾文档与非垃圾文档的特征的条件概率\n",
    "\"\"\"\n",
    "def train_docNBclassifier(x_train,y_train):\n",
    "    count = 0 \n",
    "    m = len(x_train)\n",
    "    n = len(x_train[0])\n",
    "#     for i in y_train:\n",
    "#         if i == 1: \n",
    "#             count += 1\n",
    "#     prob_0 = np.zeros(n) \n",
    "#     num0 = 0\n",
    "#     prob_1 = np.zeros(n)\n",
    "#     num1 = 0\n",
    "    # 引入拉普拉斯平滑\n",
    "    prob_0 = np.ones(n)\n",
    "    prob_1 =np.ones(n)\n",
    "    num0 = 2\n",
    "    num1 = 2\n",
    "    for i in range(m):\n",
    "        if y_train[i] == 0:\n",
    "            prob_0 += x_train[i]\n",
    "            num0 += sum(x_train[i])\n",
    "        else:\n",
    "            prob_1 += x_train[i]\n",
    "            num1 += sum(x_train[i])\n",
    "            count += 1\n",
    "#     conprob_0 = map(lambda x,y: x/y,prob_0,sum0)\n",
    "    conprob_0 = np.log(prob_0/num0)\n",
    "    conprob_1 = np.log(prob_1/num1)\n",
    "    prior_prob = count/m\n",
    "    return conprob_0,conprob_1,prior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-2.56494936, -2.56494936, -2.56494936, -3.25809654, -2.56494936,\n",
       "        -3.25809654, -2.56494936, -2.56494936, -2.56494936, -2.56494936,\n",
       "        -2.56494936, -2.56494936, -2.56494936, -3.25809654, -3.25809654,\n",
       "        -1.87180218, -2.56494936, -2.56494936, -2.56494936, -3.25809654,\n",
       "        -3.25809654, -2.56494936, -2.56494936, -2.56494936, -3.25809654,\n",
       "        -2.56494936, -3.25809654, -2.56494936, -3.25809654, -3.25809654,\n",
       "        -3.25809654, -3.25809654, -2.15948425]),\n",
       " array([-3.04452244, -1.94591015, -3.04452244, -2.35137526, -3.04452244,\n",
       "        -2.35137526, -3.04452244, -3.04452244, -2.35137526, -3.04452244,\n",
       "        -3.04452244, -3.04452244, -2.35137526, -2.35137526, -2.35137526,\n",
       "        -3.04452244, -3.04452244, -3.04452244, -3.04452244, -2.35137526,\n",
       "        -1.65822808, -3.04452244, -3.04452244, -3.04452244, -2.35137526,\n",
       "        -3.04452244, -2.35137526, -3.04452244, -2.35137526, -2.35137526,\n",
       "        -2.35137526, -2.35137526, -2.35137526]),\n",
       " 0.5)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conprob_0,conprob_1,prior_prob = train_docNBclassifier(sensVec,doc_classVec)\n",
    "conprob_0,conprob_1,prior_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. 模型测试\n",
    "def classifier_test(prob0,prob1,prior_prob,x_test):\n",
    "#     doc_dataset,doc_classVec = build_dataset()\n",
    "#     voc_list,freq_dict = build_voc_table(doc_dataset)\n",
    "#     sensVec = build_senvec(voc_list,doc_dataset)\n",
    "#     testsVec = build_senvec(voc_list,x_test)\n",
    "#     conprob_0,conprob_1,prior_prob = train_docNBclassifier(sensVec,doc_classVec)\n",
    "#     p0 = sum(reduce(lambda x,y:x*y, x_test*prob0)*(1-prior_prob))\n",
    "#     p1 = sum(reduce(lambda x,y:x*y, x_test*prob1)*prior_prob)\n",
    "    # 引入拉普拉斯平滑，因为是log概率所以连乘可以直接相加\n",
    "    p0 = np.sum((x_test * prob0))+ np.log(1-prior_prob)\n",
    "    p1 = np.sum((x_test * prob1))+ np.log(prior_prob)\n",
    "    print('p0:',p0)\n",
    "    \n",
    "    print('p1',p1)\n",
    "    if p0 > p1:\n",
    "        return 0 \n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#注意关注维度\n",
    "x_test = [['quit','buying','worthlsess','dog','food','stupid']]\n",
    "testVec = build_senvec(voc_list,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p0: -19.54857922812889\n",
      "p1 -13.702786434872701\n"
     ]
    }
   ],
   "source": [
    "result = classifier_test(conprob_0,conprob_1, prior_prob, testVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
