{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用jupyter notebook 实现决策树\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调包实现决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用sklearn-data \n",
    "# data\n",
    "from sklearn.model_selection import train_test_split\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = [\n",
    "        'sepal length', 'sepal width', 'petal length', 'petal width', 'label'\n",
    "    ]\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])\n",
    "    # print(data)\n",
    "    return data[:, :2], data[:, -1]\n",
    "\n",
    "\n",
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'grahviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-93c1a9fc34d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgrahviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'grahviz'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import grahviz\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可视化\n",
    "tree_pic = export_graphviz(clf, out_file=\"mytree.pdf\")\n",
    "with open('mytree.pdf') as f:\n",
    "    dot_graph = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3算法，利用信息增益构建决策树\n",
    "一、特征选择使用信息增益\n",
    "二、构建树\n",
    "三、剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"整理需要用到的函数\n",
    "1. 数据集获取函数（）: 输出训练集和测试集合；\n",
    "2. 训练集与测试集标准化\n",
    "3. 信息增益计算函数（训练集）：\n",
    "4. 获取最大信息增益的特征函数（训练集合）：特征维度index\n",
    "5. 递归建树（训练集）：字典树\n",
    "6. 计算模型性能（字典树头节点，测试集）\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 倒入需要的库以及数据集\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston,load_iris\n",
    "import os \n",
    "\n",
    "pwd = os.path.abspath(os.path.__file__)\n",
    "iris = load_iris()\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建规划器对训练集标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "def scaler(features,tool):\n",
    "    tool.fit(features)\n",
    "    std_features = tool.transform(features)\n",
    "    return std_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 香农熵计算函数\n",
    "def calent(dataframe):\n",
    "    num = dataframe.shape[0]\n",
    "    labels = dataframe.iloc[:,-1].value_counts()\n",
    "    p = labels/num\n",
    "    ent = sum(-p*np.log2(p))\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造测试用例，测试函数\n",
    "def createDataset():\n",
    "    testcase = {'a':[1,1,0,0,1],\n",
    "                'b':[0,0,0,1,1],\n",
    "                'labels':['yes','no','yes','yes','no']}\n",
    "    testdf = pd.DataFrame(testcase)\n",
    "    return testdf\n",
    "\n",
    "testcase = createDataset()\n",
    "ent = calent(testcase)\n",
    "ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择最大信息增益\n",
    "def infoGain(dataframe):\n",
    "    dflen = dataframe.shape[0]\n",
    "    baseEnt = calent(dataframe)\n",
    "    maxent = 0\n",
    "    axis = -1\n",
    "    for i in range(dataframe.shape[1]-1):\n",
    "        curent = 0\n",
    "        cats = dataframe.iloc[:,i].value_counts().index\n",
    "        for j in cats:\n",
    "            subdf = dataframe[dataframe.iloc[:,i] == j]\n",
    "            tempent = calent(subdf)\n",
    "            curent += (subdf.shape[0]/dflen)*tempent\n",
    "        finalEnt = baseEnt - curent\n",
    "#         print('第',i,'列的信息增益为',finalEnt)\n",
    "        if (finalEnt>maxent):\n",
    "            maxent = finalEnt\n",
    "            axis = i\n",
    "    return i             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "Name: b, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame({'a':[1,1,1,0],'b':[1,0,0,1],'c':[0,1,1,0],'lab':['yes','no','yes','no']})\n",
    "a['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis = infoGain(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#按照给定列进行数据帧切分\n",
    "\"\"\"\n",
    "函数功能：按照给定列划分数据集\n",
    "输入：\n",
    "    df:数据帧\n",
    "    axis:要切割的列\n",
    "    value: \n",
    "输出：子数据帧\n",
    "\"\"\"\n",
    "def splitdf(dataframe,axis,value):\n",
    "    col = dataframe.columns[axis]\n",
    "    # print(dataframe[col]==0)\n",
    "\n",
    "    \"\"\"选择与value匹配的行,在子数据帧中把列切掉\n",
    "    0    False\n",
    "    1     True\n",
    "    2     True\n",
    "    3    False\n",
    "    \"\"\"\n",
    "    subdf = dataframe.loc[dataframe[col] == value,:].drop(col,axis=1)\n",
    "    return subdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>lab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  lab\n",
       "0  1  1  yes\n",
       "3  0  1   no"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitdf(a,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n函数说明： 使用ID3算法递归构建决策树，递归先判断停止条件\\n输入：\\n    训练数据集D，特征集A阈值\\n输出:\\n    字典形式的树T\\n1）若D中所有实例属于一类，则T为单节点树，将C作为该节点类的标记，返回T\\n2）若特征集为空，则T为单节点树，并将D中实例最大的类C作为该节点的类标记，返回T\\n3）否则，递归计算信息增益，选择信息增益最大的列将D切割为若干非空子集D，将Di中实例数最大的类作为标记，构建子节点。由节点与其子节点\\n   构成树T\\n4）对第I个子节点，以Di为训练集，A-Ai为特征集调用1）-3），得到子树\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "函数说明： 使用ID3算法递归构建决策树，递归先判断停止条件\n",
    "输入：\n",
    "    训练数据集D，特征集A阈值\n",
    "输出:\n",
    "    字典形式的树T\n",
    "1）若D中所有实例属于一类，则T为单节点树，将C作为该节点类的标记，返回T\n",
    "2）若特征集为空，则T为单节点树，并将D中实例最大的类C作为该节点的类标记，返回T\n",
    "3）否则，递归计算信息增益，选择信息增益最大的列将D切割为若干非空子集D，将Di中实例数最大的类作为标记，构建子节点。由节点与其子节点\n",
    "   构成树T\n",
    "4）对第I个子节点，以Di为训练集，A-Ai为特征集调用1）-3），得到子树\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDecisionTree(dataset):\n",
    "#     print(dataset)\n",
    "    cols = list(dataset.columns[:-1])\n",
    "    labels = dataset.iloc[:,-1].value_counts()\n",
    "    \n",
    "    #只有一类特征或数据集只剩下一行\n",
    "    if dataset.shape[0] == 1 or len(cols)==1:\n",
    "        return labels[0]\n",
    "    else:\n",
    "        #只有一类\n",
    "        if labels.shape[0] == 1:\n",
    "            return labels[0]\n",
    "        axis = infoGain(dataset)\n",
    "        #注意定义内部变量来保存列名\n",
    "        feature = cols[axis]\n",
    "        nodeDict = {feature:{}}\n",
    "        del cols[axis]\n",
    "        cats = set(dataset.iloc[:,axis].value_counts().index)\n",
    "        print(cats)\n",
    "        for i in cats:\n",
    "#             print('i:',i,'axis:',axis)\n",
    "            subdf = splitdf(dataset,axis,i)\n",
    "#             print(subdf)\n",
    "            nodeDict[feature][i] = buildDecisionTree(subdf)\n",
    "#             print(nodeDict)\n",
    "        return nodeDict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n",
      "{1}\n",
      "{0}\n"
     ]
    }
   ],
   "source": [
    "mytree = buildDecisionTree(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明：将决策树保存为npy文件\n",
    "输入：保存路径，树\n",
    "输出：无\n",
    "\"\"\"\n",
    "file = '/Users/laurent/Desktop/学习/Staticstics_Lihang/CH05'\n",
    "def saveTree(path,treeDict):\n",
    "    np.save(os.path.join(path,'ID3Tree.npy'),treeDict)\n",
    "    print('文件保存到',os.path.join(path))\n",
    "    \n",
    "def loadTree(path):\n",
    "    tree = np.load(os.path.join(path,'ID3Tree.npy')).item()\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'函数功能： 对一个测试实例进行分类\\n输入： inputree：决策树\\n      labels：决策树特征类别序号\\n      test：测试样本\\n输出:  testRes:list 测试样本类别列表\\n      \\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用决策树进行分类\n",
    "\"\"\"函数功能： 对一个测试实例进行分类\n",
    "输入： inputree：决策树\n",
    "      labels：决策树特征类别序号\n",
    "      test：测试样本\n",
    "输出:  testRes:list 测试样本类别列表\n",
    "      \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C4.5 算法，利用信息增益比建树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1   -32.0\n",
       "0    -4.0\n",
       "Name: glasses, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#构建测试集\n",
    "test = {'bred':[1,0,1,0,1,0],'suit':[0,0,1,0,1,0],'glasses':[1,0,1,1,0,1],'label':['no','no','yes','no','yes','no']}\n",
    "test = pd.DataFrame(test)\n",
    "test['label'].value_counts().values\n",
    "sub = test.iloc[:,2].value_counts()\n",
    "-sub*sub* np.log2(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算信息增益\n",
    "\"\"\"\n",
    "函数说明： 计算数据集的熵\n",
    "输入： dataframe\n",
    "输出： 熵\n",
    "\"\"\"\n",
    "def entropycal(df):\n",
    "    labels = df['label'].value_counts().values\n",
    "    num = df.shape[0]\n",
    "    p = labels/num\n",
    "    ent = -np.sum(p * np.log2(p))\n",
    "    return ent\n",
    "\"\"\"\n",
    "函数说明：计算训练样本每一个特征的信息增益\n",
    "输入： dataframe\n",
    "\"\"\"\n",
    "def mulinfocal(df):\n",
    "    baseent = entropycal(df)\n",
    "    cats_num = len(df.columns)-1\n",
    "    totalnum = df.shape[0]\n",
    "    info = []\n",
    "    #异常判断\n",
    "    for i in range(cats_num):\n",
    "        ent = 0\n",
    "        cats = df.iloc[:,i].value_counts().index\n",
    "        for j in cats:\n",
    "            subdf = df[df.iloc[:,i] == j]\n",
    "            ent += (subdf.shape[0]/totalnum )*entropycal(subdf)\n",
    "        info.append(baseent-ent)\n",
    "    return info\n",
    "\n",
    "mulinfocal(test)\n",
    "\n",
    "\"\"\"\n",
    "函数说明： 计算训练样本每一个特征的信息增益比\n",
    "\"\"\"\n",
    "def inforatecal(df):\n",
    "    infolist = df\n",
    "    totalnum = int(df.shape[0])\n",
    "    cats_num = len(df.columns)-1\n",
    "    infolist = mulinfocal(df)\n",
    "    hlist = []\n",
    "    for i in range(cats_num):\n",
    "        diffvalues = df.iloc[:,i].value_counts()\n",
    "        nums = diffvalues.shape[0]\n",
    "#         print(diffvalues/totalnum)\n",
    "        p = diffvalues/totalnum\n",
    "#         print(p)\n",
    "        finalh = np.sum(-p*p*np.log2(p), axis=0)\n",
    "#         print(finalh)\n",
    "        hlist.append(finalh)\n",
    "#     print(hlist)\n",
    "#     print(infolist)\n",
    "    # 对两个列表每一个元素进行操作\n",
    "    inforate = list(map((lambda x:x[0]/x[1]),zip(infolist, hlist)))\n",
    "#     inforate = infolist ./ hlist     \n",
    "    idx = inforate.index(max(inforate))\n",
    "    return idx\n",
    "# 验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     no\n",
       "1     no\n",
       "2    yes\n",
       "3     no\n",
       "4    yes\n",
       "5     no\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试C4.5 的\n",
    "def BuilDTree_C4(dataset):\n",
    "#     print(dataset)\n",
    "    cols = list(dataset.columns[:-1])\n",
    "    labels = dataset.iloc[:,-1].value_counts()\n",
    "    \n",
    "    #只有一类特征或数据集只剩下一行\n",
    "    if dataset.shape[0] == 1 or len(cols)==1:\n",
    "        return labels.index[0]\n",
    "    else:\n",
    "        #只有一类\n",
    "        if labels.shape[0] == 1:\n",
    "            return labels[0]\n",
    "        axis = inforatecal(dataset)\n",
    "        #注意定义内部变量来保存列名\n",
    "        feature = cols[axis]\n",
    "        nodeDict = {feature:{}}\n",
    "        del cols[axis]\n",
    "        cats = set(dataset.iloc[:,axis].value_counts().index)\n",
    "        print(cats)\n",
    "        for i in cats:\n",
    "#             print('i:',i,'axis:',axis)\n",
    "            subdf = splitdf(dataset, axis, i)\n",
    "#             print(subdf)\n",
    "            nodeDict[feature][i] = buildDecisionTree(subdf)\n",
    "#             print(nodeDict)\n",
    "        return nodeDict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n",
      "{0, 1}\n",
      "{0, 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'glasses': {0: {'suit': {0: 1, 1: 1}}, 1: {'suit': {0: 3, 1: 1}}}}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildDecisionTree(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "# 选择信息增益比最大的列进行切分\n",
    "# def splitdf(df, idx):\n",
    "#     col = cols[idx]\n",
    "#     subdf = test.drop(columns=col)\n",
    "#     return subdf\n",
    "# # splitdf(test)\n",
    "# test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建树结构搭建决策树\n",
    "\"\"\"\n",
    "考虑好节点结构，以及特征，特征idx的存储，切分后的子集的遍历存储\n",
    "\"\"\"\n",
    "class Node:\n",
    "    def __init__(self, root=True, label=True, Feature_name=None. feature=None)\n",
    "        self.root = root \n",
    "        self.label = label\n",
    "        self,feature_name = feature_name\n",
    "        self.feature = feature\n",
    "        self.tree = {}\n",
    "        self.result = {\n",
    "            'label': self.label,\n",
    "            'feature' : self.feature,\n",
    "            'tree' : self.tree\n",
    "        }\n",
    "    def __repr__(self):\n",
    "        return '{}'.format(self.result)\n",
    "    \n",
    "    def add_node(self, val, node):\n",
    "        self.tree[val] = node\n",
    "    \n",
    "    def predic(self, features):\n",
    "        if self.root is True:\n",
    "            return self.label\n",
    "        return self.tree[features[self.feature]].predict(features)\n",
    "\n",
    "class DTree:\n",
    "    def __init__(self, epsilon=0.1):\n",
    "        self.epsilon = epsilon\n",
    "        self.tree = {}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART 算法，利用基尼指数建树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基尼指数算法计算最佳切分特征\n",
    "\"\"\"\n",
    "统计数据帧中label的种类与对应的数量，计算概率p， gini = 1-sum((pi)*2)\n",
    "表示集合的不确定性，gini越大，不确定性越高\n",
    "在二叉分类树中，只做二分类的gini计算，按二分类形式，对该特征该值进行树的构建；\n",
    "\"\"\"\n",
    "def ginical(df):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树剪枝算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.计算节点的损失函数\n",
    "#### 2. 树剪枝\n",
    "#### 3. 遍历新树进行剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-129-3af7a3c4d1bd>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-129-3af7a3c4d1bd>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    cols = traindf.colums()\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "函数说明：遍历一个树的所有节点，直到叶子节点计算损失函数， 不好实现\n",
    "输入：根节点\n",
    "\n",
    "\"\"\"\n",
    "def getrootloss(traindf, inputTree):\n",
    "    firstStr = list(inputTree.keys())[0]\n",
    "    secodDict = inputTree[firstStr]\n",
    "    total_num = 0\n",
    "    for key in list(secondDict.keys()):\n",
    "        if isTree(secondDict[key]):\n",
    "            #继续递归\n",
    "            \n",
    "    cols = traindf.colums()\n",
    "    feature_idx = col.index(firstStr)\n",
    "    cats = traindf[firstStr].value_counts().values.tolist()\n",
    "    totalinfo = 0.0\n",
    "    for cat in cats:\n",
    "        subdf = traindf[traindf[firstStr] == cat]\n",
    "        subdfnum = subdf.shape[0]\n",
    "        labels = subdf.iloc[-1].value_counts()\n",
    "        p = labels.iloc[0]/subdfnum\n",
    "        info = -1* np.sum(p*np.log2(p))\n",
    "        totalinfo += info\n",
    "    return totalinfo\n",
    "def info(df):\n",
    "    return calent(df)\n",
    "\n",
    "def get_gt(rootloos, leafent, nodesnum):\n",
    "    gt = (ent - getrootloss)/ (nodesnum-1)\n",
    "\n",
    "def splitDataSet(df, col_idx, value):\n",
    "    subdf = df[df.iloc[:, col_idx] == value]\n",
    "    return subdf\n",
    "\n",
    "def pruneTree(inputTree, traindf, testdf):\n",
    "    \n",
    "    \"\"\"\n",
    "    输入： 决策树，训练集\n",
    "    输出： 剪枝子树列表\n",
    "    获取树的key，递归计算，判断字典子集是否是树，如果是的话就继续递归切分（数据集和测试集也要切分），直到子树都是叶子节点，计算分类错误率，\n",
    "        如果分类错误率降低，那么替换树，变为节点（多数分类规则进行归类），返回类别就可。\n",
    "    \"\"\"\n",
    "    \n",
    "    firstStr = list(inputTree.keys())[0]\n",
    "    secondDict = inputTree[firstStr]        # 获取子树\n",
    "    num_cats = len(secondDict)\n",
    "    totalinfo = 0.0\n",
    "    labels = traindf.iloc[:, -1]\n",
    "#     featKey = copy.deepcopy(firstStr)  \n",
    "#     labelIndex = labels.index(featKey)  \n",
    "#     subLabels = copy.deepcopy(labels)\n",
    "#     del(labels[labelIndex])  \n",
    "    for key in list(secondDict.keys()):  \n",
    "        if isTree(secondDict[key]):\n",
    "            # 深度优先搜索,递归剪枝\n",
    "            subDataSet = splitDataSet(dataSet,labelIndex,key)\n",
    "            subTestSet = splitDataSet(testData,labelIndex,key)\n",
    "            if len(subDataSet) > 0 and len(subTestSet) > 0:\n",
    "                inputTree[firstStr][key] = pruneTree(secondDict[key],subDataSet,subTestSet,copy.deepcopy(labels))\n",
    "    if calcTestErr(inputTree,testData,subLabels) < testMajor(majorityCnt(classList),testData):\n",
    "        # 剪枝后的误差反而变大，不作处理，直接返回\n",
    "        return inputTree \n",
    "    else:\n",
    "        # 剪枝，原父结点变成子结点，其类别由多数表决法决定\n",
    "        return majorityCnt(classList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
